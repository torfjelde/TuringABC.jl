var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [TuringABC]","category":"page"},{"location":"api/#TuringABC.ABC","page":"API","title":"TuringABC.ABC","text":"ABC <: AbstractMCMC.AbstractSampler\n\nApproximate Bayesian Computation (ABC) sampler.\n\nFields\n\ndist_and_stat: distance and statistic method expecting two arguments: data_true and data_proposed\nthreshold_initial: initial threshold used for comparison to decide whether to accept or reject\nthreshold_minimum: final threshold used for comparison to decide whether to accept or reject\nthreshold_decay: factor by which to decrease the threshold\n\nNotes\n\nThe current implementation uses a schedule for decreasing the threshold that is\n\nepsilon_i+1 = epsilon_i cdot fracii+1^textthreshold_decay\n\nwhere i is the current iteration and \\theta is the current threshold.\n\nWhether or not this is a good idea, I don't know! But it's trying to achieve a behavior where the threshold decreases rapidly at the first, and then more slowly for later iterations.\n\n\n\n\n\n","category":"type"},{"location":"api/#TuringABC.DiracDelta","page":"API","title":"TuringABC.DiracDelta","text":"DiracDelta(value)\n\nA Dirac delta distribution with a single point mass at value.\n\nThis is basically the same as Distributions.Dirac but without being restricted to univariate values.\n\n\n\n\n\n","category":"type"},{"location":"api/#TuringABC.flatten-Tuple{Any}","page":"API","title":"TuringABC.flatten","text":"flatten(x)\n\nReturn a flattened version of x.\n\n\n\n\n\n","category":"method"},{"location":"api/#TuringABC.make_joint_model-Tuple{ABC, DynamicPPL.Model}","page":"API","title":"TuringABC.make_joint_model","text":"make_joint_model(sampler::ABC, model::DynamicPPL.Model)\n\nReturn a model with observations now also considered random variables.\n\n\n\n\n\n","category":"method"},{"location":"api/#TuringABC.observations-Tuple{ABC, DynamicPPL.Model}","page":"API","title":"TuringABC.observations","text":"observations(sampler::ABC, model::DynamicPPL.Model)\n\nReturn the observations in model.\n\n\n\n\n\n","category":"method"},{"location":"api/#TuringABC.sample_from_joint-Tuple{Random.AbstractRNG, ABC, DynamicPPL.Model}","page":"API","title":"TuringABC.sample_from_joint","text":"sample_from_joint(rng::Random.AbstractRNG, sampler::ABC, model::DynamicPPL.Model)\n\nSample from the joint model.\n\nDefaults to rand(rng, OrderedDict, make_joint_model(sampler, model)).\n\nSee also: make_joint_model.\n\n\n\n\n\n","category":"method"},{"location":"api/#TuringABC.split_latent_data-Tuple{OrderedCollections.OrderedDict, Any, Any}","page":"API","title":"TuringABC.split_latent_data","text":"split_latent_data(d::OrderedDict, data_variables, data)\n\nReturn a 3-tuple with first element being variables, second being sampled data, and third being the original data.\n\nThe original data returned should be in the same format as the data sampled.\n\n\n\n\n\n","category":"method"},{"location":"api/#TuringABC.statistic_distance-Tuple{ABC, Any, Any}","page":"API","title":"TuringABC.statistic_distance","text":"statistic_distance(sampler::ABC, data_true, data_candidate)\n\nReturn the distance between the statistics of data_true and data_candidate.\n\n\n\n\n\n","category":"method"},{"location":"api/#TuringABC.statistic_distance-Tuple{ABC, DynamicPPL.Model, Any}","page":"API","title":"TuringABC.statistic_distance","text":"statistic_distance(sampler::ABC, model::DynamicPPL.Model, data_candidate)\n\nReturn the distance between observations in model and data_candidate.\n\n\n\n\n\n","category":"method"},{"location":"api/#TuringABC.varname_keys-Tuple{AbstractDict}","page":"API","title":"TuringABC.varname_keys","text":"varname_keys(x)\n\nLike keys(x), but returns a collection of VarName instead of Symbol.\n\n\n\n\n\n","category":"method"},{"location":"getting-started/#Getting-started","page":"Getting started","title":"Getting started","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"First we define a model with Turing.jl.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"using Turing\n\n# Example model.\n@model function demo()\n    x ~ Normal()\n    y ~ Normal(x, 1)\nend\n\nmodel = demo() | (y = 2.0, )","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"warning: Warning\nTuringABC currently only supports conditioning of the form model | (...) or condition(model, ...). That is, passing conditioned variables as inputs to the model is NOT supported (yet).","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Let's sample with NUTS first to have something to compare to","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"samples_nuts = sample(model, NUTS(), 1_000)","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Now we do ABC:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"using TuringABC\n\nspl = ABC(0.1)\nsamples = sample(model, spl, 10_000; chain_type=MCMCChains.Chains)","category":"page"},{"location":"getting-started/#More-complex-example","page":"Getting started","title":"More complex example","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Now we're going to try something a bit more crazy: we'll run inference within a model outer_model, and then run inference over this! Yes, you read that right: inference-within-inference.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"warning: Warning\nThis is not something we recommend doing; this is just a demo of what one could do!","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"using Turing, TuringABC, LinearAlgebra, Logging\nusing Turing.DynamicPPL","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"First we define the inner_model, i.e. the model we're going to do inference over within outer_model.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"@model function inner_model(σ², N)\n    x ~ MvNormal(zeros(N), I)\n    y_inner ~ MvNormal(x, σ² * I)\nend","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Then we need a method which can convert the resulting approximation of the posterior of inner_model into some statistics that we can use as \"observation\" for the approximate posterior:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"function f_default(samples::MCMCChains.Chains)\n    # Use quantiles of the \"posterior\" (approximated by `samples`)\n    return vec(mapreduce(Base.Fix2(quantile, [0.25, 0.5, 0.75]), hcat, eachcol(Array(samples))))\nend","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Now we can finally define the outer_model!","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"@model function outer_model(\n    μ;\n    f=f_default,\n    # Sampler and number of samples for the inner model.\n    # We'll use NUTS by default, but this will be expensive!\n    inner_sampler=NUTS(),\n    num_inner_samples=1000,\n)\n    N = length(μ)\n    # Prior on the variance used.\n    σ² ~ InverseGamma(2, 1)\n    # Prior on the mean used.\n    y ~ MvNormal(μ, σ² * I)\n    # Obtain (approximate) posterior of the inner model conditioned\n    # on the sampled `y` from above.\n    inner_mdl = inner_model(σ², N) | (y_inner = y,)\n    # Turn off logging for this inner sample since it will be called many times.\n    posterior = with_logger(NullLogger()) do\n        sample(inner_mdl, inner_sampler, num_inner_samples; chain_type=MCMCChains.Chains, progress=false)\n    end\n    # Since we're now working with an empirical approximation of the\n    # posterior, we project `posterior` (usually samples) onto some statistics\n    # using `f`, and then this we'll fix/condition to some value later.\n    stat ~ DiracDelta(f(posterior))\n\n    return (; posterior, stat)\nend","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"# Let's generate some data.\nμ = zeros(2)\nmodel = outer_model(μ)\n\nvars_true = (σ² = 1.0, y = 0.5 .* ones(length(μ)))\nstat_true = rand(condition(model, vars_true)).stat","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"# Now condition the model on the true statistic.\nconditioned_model = model | (stat = stat_true,)\n# Now if we sample from it there is no `stat`.\nrand(conditioned_model)","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"# We can now use ABC to sample.\n# NOTE: This will take a few minutes to run since we're running NUTS in every ABC iteration.\nchain = sample(\n    conditioned_model,\n    ABC(threshold_initial=1.0, threshold_minimum=1e-2, threshold_decay=0.5),\n    1000;\n    discard_initial=1000,\n    chain_type=MCMCChains.Chains,\n    progress=true\n)","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"quantile(chain)","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"using StatsPlots\nplot(chain)","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"This is clearly not working very well:) But hey, at least it's possible!","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = TuringABC","category":"page"},{"location":"#TuringABC","page":"Home","title":"TuringABC","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"TuringABC is a simple implementation of Approximate Bayesian Inference (ABC) in a way compatible with Turing.jl-models.","category":"page"}]
}
